{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c428871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from minepy import MINE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'cal_rd_data_high_variance.csv'\n",
    "all_data = pd.read_csv(file_path)\n",
    "data = all_data.iloc[:,all_data.columns != \"index\" ]\n",
    "descriptor_data = data.iloc[:,data.columns != \"Water_all_overlap_factor_100\"]\n",
    "all_data_name_list = list(all_data)\n",
    "descriptor_name_list = list(descriptor_data)\n",
    "descriptor_count = len(descriptor_name_list)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaler = scaler.fit_transform(data)\n",
    "DataFrame_data_scaler = pd.DataFrame(data_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc298c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pearson = DataFrame_data_scaler.corr(method = 'pearson')\n",
    "data_spearman = DataFrame_data_scaler.corr(method = 'spearman')\n",
    "mine = MINE(alpha=0.6, c=15)\n",
    "\n",
    "def distcorr(X, Y):\n",
    "    X = np.atleast_1d(X)\n",
    "    Y = np.atleast_1d(Y)\n",
    "    if np.prod(X.shape) == len(X):\n",
    "        X = X[:, None]\n",
    "    if np.prod(Y.shape) == len(Y):\n",
    "        Y = Y[:, None]\n",
    "    X = np.atleast_2d(X)\n",
    "    Y = np.atleast_2d(Y)\n",
    "    n = X.shape[0]\n",
    "    if Y.shape[0] != X.shape[0]:\n",
    "        raise ValueError('Number of samples must match')\n",
    "    a = squareform(pdist(X))\n",
    "    b = squareform(pdist(Y))\n",
    "    A = a - a.mean(axis=0)[None, :] - a.mean(axis=1)[:, None] + a.mean()\n",
    "    B = b - b.mean(axis=0)[None, :] - b.mean(axis=1)[:, None] + b.mean()\n",
    "\n",
    "    dcov2_xy = (A * B).sum() / float(n * n)\n",
    "    dcov2_xx = (A * A).sum() / float(n * n)\n",
    "    dcov2_yy = (B * B).sum() / float(n * n)\n",
    "    dcor = np.sqrt(dcov2_xy) / np.sqrt(np.sqrt(dcov2_xx) * np.sqrt(dcov2_yy))\n",
    "    return dcor\n",
    "\n",
    "column_descriptor = data_scaler.shape[1]\n",
    "\n",
    "Threshold = 0.00001\n",
    "pearson_correlation_list = []\n",
    "pearson_pvalue_list = []\n",
    "pearson_selection_list = []\n",
    "pearson_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    pearson_correlation_list.append(scipy.stats.pearsonr(data_scaler[:,i],data_scaler[:,0])[0])\n",
    "    pearson_pvalue_list.append(scipy.stats.pearsonr(data_scaler[:,i],data_scaler[:,0])[1])\n",
    "    if pearson_pvalue_list[i-1] > Threshold:\n",
    "        pearson_selection_list.append(0)\n",
    "    else :\n",
    "        pearson_selection_list.append(1)\n",
    "pearson_list.append(pearson_correlation_list)\n",
    "pearson_list.append(pearson_pvalue_list)\n",
    "pearson_list.append(pearson_selection_list)\n",
    "\n",
    "Threshold = 0.00001\n",
    "spearman_correlation_list = []\n",
    "spearman_pvalue_list = []\n",
    "spearman_selection_list = []\n",
    "spearman_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    spearman_correlation_list.append(scipy.stats.spearmanr(data_scaler[:,i],data_scaler[:,0])[0])\n",
    "    spearman_pvalue_list.append(scipy.stats.spearmanr(data_scaler[:,i],data_scaler[:,0])[1])\n",
    "    if spearman_pvalue_list[i-1] > Threshold:\n",
    "        spearman_selection_list.append(0)\n",
    "    else :\n",
    "        spearman_selection_list.append(1)\n",
    "spearman_list.append(spearman_correlation_list)\n",
    "spearman_list.append(spearman_pvalue_list)\n",
    "spearman_list.append(spearman_selection_list)\n",
    "\n",
    "Threshold = 0.33\n",
    "distance_correlation_list = []\n",
    "distance_selection_list = []\n",
    "distance_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    distance_correlation_list.append(distcorr(data_scaler[:,i],data_scaler[:,0]))\n",
    "    if abs(distance_correlation_list[i-1]) <= Threshold:\n",
    "        distance_selection_list.append(0)\n",
    "    else :\n",
    "        distance_selection_list.append(1)\n",
    "distance_list.append(distance_correlation_list)\n",
    "distance_list.append(distance_selection_list)\n",
    "\n",
    "Threshold = 0.33\n",
    "mic_correlation_list = []\n",
    "mic_selection_list = []\n",
    "mic_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    mine.compute_score(data_scaler[:,i],data_scaler[:,0])\n",
    "    mic_correlation_list.append(mine.mic())\n",
    "    if abs(mic_correlation_list[i-1]) <= Threshold:\n",
    "        mic_selection_list.append(0)\n",
    "    else:\n",
    "        mic_selection_list.append(1)\n",
    "mic_list.append(mic_correlation_list)\n",
    "mic_list.append(mic_selection_list)\n",
    "\n",
    "sum_list = []\n",
    "for j in range(0,descriptor_count):\n",
    "    sum_list.append(pearson_selection_list[j] + spearman_selection_list[j] + distance_selection_list[j] + mic_selection_list[j])\n",
    "\n",
    "sum_selection_list1 = []\n",
    "Threshold1 = 1\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold1:\n",
    "        sum_selection_list1.append(1)\n",
    "    else:\n",
    "        sum_selection_list1.append(0)\n",
    "sum(sum_selection_list1)\n",
    "\n",
    "sum_selection_list2 = []\n",
    "Threshold2 = 2\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold2:\n",
    "        sum_selection_list2.append(1)\n",
    "    else:\n",
    "        sum_selection_list2.append(0)\n",
    "sum(sum_selection_list2)\n",
    "\n",
    "sum_selection_list3 = []\n",
    "Threshold3 = 3\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold3:\n",
    "        sum_selection_list3.append(1)\n",
    "    else:\n",
    "        sum_selection_list3.append(0)\n",
    "sum(sum_selection_list3)\n",
    "\n",
    "sum_selection_list4 = []\n",
    "Threshold4 = 4\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold4:\n",
    "        sum_selection_list4.append(1)\n",
    "    else:\n",
    "        sum_selection_list4.append(0)\n",
    "sum(sum_selection_list4)\n",
    "\n",
    "sum_list_all = []\n",
    "sum_list_all.append(sum_selection_list1)\n",
    "sum_list_all.append(sum_selection_list2)\n",
    "sum_list_all.append(sum_selection_list3)\n",
    "sum_list_all.append(sum_selection_list4)\n",
    "sum_list_all.append(sum_list)\n",
    "selection_list_all = []\n",
    "selection_list_all.append(descriptor_name_list)\n",
    "selection_list_all.append(pearson_list[0])\n",
    "selection_list_all.append(pearson_list[1])\n",
    "selection_list_all.append(pearson_list[2])\n",
    "selection_list_all.append(spearman_list[0])\n",
    "selection_list_all.append(spearman_list[1])\n",
    "selection_list_all.append(spearman_list[2])\n",
    "selection_list_all.append(distance_list[0])\n",
    "selection_list_all.append(distance_list[1])\n",
    "selection_list_all.append(mic_list[0])\n",
    "selection_list_all.append(mic_list[1])\n",
    "selection_list_all.append(sum_list_all[0])\n",
    "selection_list_all.append(sum_list_all[1])\n",
    "selection_list_all.append(sum_list_all[2])\n",
    "selection_list_all.append(sum_list_all[3])\n",
    "selection_list_all.append(sum_list_all[4])\n",
    "selection_list_all = pd.DataFrame(selection_list_all)\n",
    "\n",
    "selection_list_all_transpose = selection_list_all.T\n",
    "selection_list_all_transpose.rename(columns={0:'descriptor_name',1:'pearson_correlation',2:'pearson_pvalue',3:'pearson_selection',\n",
    "                                             4:'spearman_correlation',5:'spearman_pvalue',6:'spearman_selection',7:'distance_correlation',\n",
    "                                             8:'distance_selection',9:'mic_correlation',10:'mic_selection',11:'sum_1',\n",
    "                                             12:'sum_2',13:'sum_3',14:'sum_4',15:'sum'},inplace=True)\n",
    "\n",
    "filter_data1 = all_data\n",
    "for k in range(0,len(sum_selection_list1)):\n",
    "    if sum_selection_list1[k] == 0:\n",
    "        filter_data1 = filter_data1.drop(descriptor_name_list[k],axis=1)\n",
    "\n",
    "filter_data2 = all_data\n",
    "for k in range(0,len(sum_selection_list2)):\n",
    "    if sum_selection_list2[k] == 0:\n",
    "        filter_data2 = filter_data2.drop(descriptor_name_list[k],axis=1)\n",
    "\n",
    "filter_data3 = all_data\n",
    "for k in range(0,len(sum_selection_list3)):\n",
    "    if sum_selection_list3[k] == 0:\n",
    "        filter_data3 = filter_data3.drop(descriptor_name_list[k],axis=1)\n",
    "\n",
    "filter_data4 = all_data\n",
    "for k in range(0,len(sum_selection_list4)):\n",
    "    if sum_selection_list4[k] == 0:\n",
    "        filter_data4 = filter_data4.drop(descriptor_name_list[k],axis=1)\n",
    "\n",
    "selection_list_all_transpose.to_csv('selection_list_all_transpose.csv')\n",
    "filter_data1.to_csv('filter_data1.csv')\n",
    "filter_data2.to_csv('filter_data2.csv')\n",
    "filter_data3.to_csv('filter_data3-selected.csv')\n",
    "filter_data4.to_csv('filter_data4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9905a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:male]",
   "language": "python",
   "name": "conda-env-male-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
